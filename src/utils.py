"""
ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã€ç”»é¢è¡¨ç¤ºä»¥å¤–ã®æ§˜ã€…ãªé–¢æ•°å®šç¾©ã®ãƒ•ã‚¡ã‚¤ãƒ«ã§ã™ã€‚
"""

############################################################
# ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®èª­ã¿è¾¼ã¿
############################################################
import os
from dotenv import load_dotenv
import streamlit as st
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.schema import HumanMessage
from langchain_openai import ChatOpenAI
from langchain.chains import create_history_aware_retriever, create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
import constants as ct
from filter_extraction_llm import extract_filters_from_text

############################################################
# è¨­å®šé–¢é€£
############################################################
# ã€Œ.envã€ãƒ•ã‚¡ã‚¤ãƒ«ã§å®šç¾©ã—ãŸç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()


############################################################
# é–¢æ•°å®šç¾©
############################################################
def extract_department_name(chat_message):
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã«å«ã¾ã‚Œã‚‹éƒ¨ç½²åã‚’æŠ½å‡ºã™ã‚‹ï¼ˆç°¡æ˜“ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ä¸€è‡´ï¼‰

    Args:
        chat_message: ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸

    Returns:
        éƒ¨ç½²åï¼ˆä¾‹ï¼šã€Œäººäº‹éƒ¨ã€ï¼‰ã¾ãŸã¯ None
    """
    departments = ["äººäº‹éƒ¨", "å–¶æ¥­éƒ¨", "ITéƒ¨", "ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°éƒ¨", "çµŒç†éƒ¨", "ç·å‹™éƒ¨"]
    for dept in departments:
        if dept in chat_message:
            return dept
    return None

def get_source_icon(source):
    """
    ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ä¸€ç·’ã«è¡¨ç¤ºã™ã‚‹ã‚¢ã‚¤ã‚³ãƒ³ã®ç¨®é¡ã‚’å–å¾—

    Args:
        source: å‚ç…§å…ƒã®ã‚ã‚Šã‹

    Returns:
        ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ä¸€ç·’ã«è¡¨ç¤ºã™ã‚‹ã‚¢ã‚¤ã‚³ãƒ³ã®ç¨®é¡
    """
    # å‚ç…§å…ƒãŒWebãƒšãƒ¼ã‚¸ã®å ´åˆã¨ãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã§ã€å–å¾—ã™ã‚‹ã‚¢ã‚¤ã‚³ãƒ³ã®ç¨®é¡ã‚’å¤‰ãˆã‚‹
    if source.startswith("http"):
        icon = ct.LINK_SOURCE_ICON
    else:
        icon = ct.DOC_SOURCE_ICON
    
    return icon


def build_error_message(message):
    """
    ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ç®¡ç†è€…å•ã„åˆã‚ã›ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®é€£çµ

    Args:
        message: ç”»é¢ä¸Šã«è¡¨ç¤ºã™ã‚‹ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸

    Returns:
        ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ç®¡ç†è€…å•ã„åˆã‚ã›ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®é€£çµãƒ†ã‚­ã‚¹ãƒˆ
    """
    return "\n".join([message, ct.COMMON_ERROR_MESSAGE])

def is_employee_query(chat_message):
    """
    å…¥åŠ›ãŒç¤¾å“¡æƒ…å ±ã«é–¢ã™ã‚‹è³ªå•ã‹ã©ã†ã‹ã‚’åˆ¤å®šï¼ˆç°¡æ˜“çš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒï¼‰
    """
    keywords = [
        "ç¤¾å“¡", "å¾“æ¥­å“¡", "äººäº‹", "æ‰€å±", "éƒ¨ç½²",
        "ãƒ¡ãƒ³ãƒãƒ¼", "ä¸€è¦§", "ã‚¹ã‚¿ãƒƒãƒ•", "äººå“¡"
    ]
    return any(keyword in chat_message for keyword in keywords)

def get_llm_response(chat_message):
    """
    LLMã‹ã‚‰ã®å›ç­”å–å¾—

    Args:
        chat_message: ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›å€¤

    Returns:
        LLMã‹ã‚‰ã®å›ç­”
    """
    # LLMã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ç”¨æ„
    llm = ChatOpenAI(model_name=ct.MODEL, temperature=ct.TEMPERATURE)

    # ä¼šè©±å±¥æ­´ãªã—ã§ã‚‚LLMã«ç†è§£ã—ã¦ã‚‚ã‚‰ãˆã‚‹ã€ç‹¬ç«‹ã—ãŸå…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ã™ã‚‹ãŸã‚ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½œæˆ
    question_generator_template = ct.SYSTEM_PROMPT_CREATE_INDEPENDENT_TEXT
    question_generator_prompt = ChatPromptTemplate.from_messages(
        [
            ("system", question_generator_template),
            MessagesPlaceholder("chat_history"),
            ("human", "{input}")
        ]
    )

    # ãƒ¢ãƒ¼ãƒ‰ã«ã‚ˆã£ã¦LLMã‹ã‚‰å›ç­”ã‚’å–å¾—ã™ã‚‹ç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å¤‰æ›´
    if st.session_state.mode == ct.ANSWER_MODE_1:
        question_answer_template = ct.SYSTEM_PROMPT_DOC_SEARCH
    else:
        question_answer_template = ct.SYSTEM_PROMPT_INQUIRY

    question_answer_prompt = ChatPromptTemplate.from_messages(
        [
            ("system", question_answer_template),
            MessagesPlaceholder("chat_history"),
            ("human", "{input}")
        ]
    )

    # === retrieverã‚’ç¤¾å“¡ã‹æ–‡æ›¸ã‹ã§åˆ‡ã‚Šæ›¿ãˆ ===
    if is_employee_query(chat_message):
        retriever = st.session_state.employee_retriever

        # ğŸ”¹ LLMã§ãƒ•ã‚£ãƒ«ã‚¿æŠ½å‡º
        filters = extract_filters_from_text(chat_message)

        # âœ… ãƒ•ã‚£ãƒ«ã‚¿ã‚­ãƒ¼ã®ãƒãƒƒãƒ”ãƒ³ã‚°å¤‰æ›
        key_mapping = {
            "éƒ¨ç½²": "department",
            "å¾“æ¥­å“¡åŒºåˆ†": "employment_type"  # ä»Šå¾Œã®æ‹¡å¼µã‚’è¦‹æ®ãˆã¦ã€è‹±èªã«çµ±ä¸€
        }      
        converted_filters = {key_mapping.get(k, k): v for k, v in filters.items() if v}

        # ğŸ”¹ ãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶ã‚’ç”»é¢ã«è¡¨ç¤ºï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã«æ˜ç¤ºï¼‰
        if filters:
            st.markdown("#### ğŸ§  AIãŒæŠ½å‡ºã—ãŸæ¤œç´¢æ¡ä»¶")
            for key, value in filters.items():
                if value:
                    st.markdown(f"- **{key}**: {value}")
            st.markdown("ï¼ˆâ€»æ¡ä»¶ãŒæ„å›³ã¨é•ã†å ´åˆã¯ã€ä¿®æ­£ã—ã¦å†å…¥åŠ›ã—ã¦ãã ã•ã„ï¼‰")

            # ğŸ”¹ æ¤œç´¢ãƒ•ã‚£ãƒ«ã‚¿ã«åæ˜ 
            retriever.search_kwargs["filter"] = {
                "$and": [{"category": "employee"}] + [{k: v} for k, v in converted_filters.items()]
            }

            # ğŸ” ãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶ã‚’ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›
            print("[DEBUG] è¨­å®šã•ã‚ŒãŸæ¤œç´¢ãƒ•ã‚£ãƒ«ã‚¿:", retriever.search_kwargs["filter"])
    else:
        retriever = st.session_state.full_retriever

    # retriever ã«åŸºã¥ã„ã¦ chain ã‚’æ§‹ç¯‰
    history_aware_retriever = create_history_aware_retriever(
        llm, retriever, question_generator_prompt
    )

    question_answer_chain = create_stuff_documents_chain(llm, question_answer_prompt)

    chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)

    # LLMã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¨ãƒ¬ã‚¹ãƒãƒ³ã‚¹å–å¾—
    llm_response = chain.invoke({
        "input": chat_message,
        "chat_history": st.session_state.chat_history
    })

    # ä¼šè©±å±¥æ­´ã«è¿½åŠ 
    st.session_state.chat_history.extend([
        HumanMessage(content=chat_message),
        llm_response["answer"]
    ])

    return llm_response

